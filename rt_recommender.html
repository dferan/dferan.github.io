<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- BS Stylesheet -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-F3w7mX95PdgyTmZZMECAngseQB83DfGTowi0iMjiWaeVhAn4FJkqJByhZMI3AhiU" crossorigin="anonymous">
    <!-- Custom stylesheet -->
    <link rel='stylesheet' type='text/css' href='github_pages.css'>

    <!-- Title --> 
    <title> dferan -- RT Recommender</title>
  </head>


  <body>
    <header>
      <div class="collapse bg-dark" id="navbarHeader">
        <div class="container">
          <div class="row">
            <div class="col-sm-8 col-md-7 py-4">
              <h4 class="text-white" id="description">Portfolio</h4>
              <p class="text-muted">This site contains a collection of projects related to data science and information studies. Check out the READ(about)ME <a href='about_me.html'>here</a>.</p>
            </div>
            <div class="col-sm-4 offset-md-1 py-4">
              <h4 class="text-white">Contact</h4>
              <ul class="list-unstyled">
                <li><a href="https://www.linkedin.com/in/darragh-feran-697760202" target='_blank' class="text-white">Contact me on LinkedIn</a></li>
              </ul>
            </div>
          </div>
        </div>
      </div>
      <div class="navbar navbar-dark bg-dark shadow-sm">
        <div class="container">
          <a href="index.html" class="navbar-brand d-flex align-items-center"><strong>dferan</strong></a>

          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarHeader" aria-controls="navbarHeader" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span> 
          </button>
        </div>
      </div>
    </header>

    <!-- Main Content -->
    <main class="py-5 container">

      <!-- Title Card -->
      <div class="p-4 p-md-5 mb-4 text-white rounded bg-dark">
        <div class="col-md-12 px-0 text-center">
          <h1 class="display-4 fst-italic">Building a Rotten Tomatoes Recommender</h1>
          <img class='img-fluid' src='images/rt_recommender/tomatoes_banner.png'> 
          <p class="lead my-3">From scratch, with scrapy, Selenium and sklearn</p>
          <br>
          <a href="https://share.streamlit.io/dferan/rt_recommender/main/rt_rec_app.py" class="btn btn-secondary" role="button" target='_blank' id='first_demo_link'>Try it out!</a>

          <p class="blog-post-meta pt-4">September 2021 </p>
        </div>
      </div>

      <!-- Article Section -->
      <div class="container">
        <article class="blog-post">

          <!-- First Section -->
          <h3 class="blog-post-title">Introduction and Motivation</h3>
          <hr>
          <p>Originally the intent was to create a system for recommending movie critics based on user alignment, so that users could be connected with reviewers who share their tastes.</p>

          <p> Rotten Tomatoes’ extensive collection of reviewers, reviews and movies was a good source of data. At some point, I shifted to a more traditional recommender system for movies; it was easier to evaluate the recommendations for movies than for critics, movies being a more familiar domain. It was also more useful. </p>


          <!-- Second Section -->
          <h3 class="blog-post-title">Recommender Basics </h3>
          <hr>
          <p>Briefly, an item-item recommender system recommends items to users based on data related to the items. These recommendations can be based on similarities between the items themselves ("<a href='https://en.wikipedia.org/wiki/Recommender_system#Content-based_filtering' target='_blank'>content-based</a>") or based on the interactions of users with the set of items ("<a href='https://en.wikipedia.org/wiki/Collaborative_filtering' target='_blank'>collaborative-filtering</a>"). We’ll explore both approaches. (For more information on theory and implementation of recommender systems, "<a href='https://learning.oreilly.com/library/view/hands-on-recommendation-systems/9781788993753/' target='_blank'>Hands-On Recommender Systems</a>” by Rounak Banik is a useful guide.)</p>

          <p>In short, both approaches seem necessary here. Collaborative filtering has many advantages, but by itself it fails to capture relevant factual similarities necessary for strong recommendations (like plot).  </p>


          <!-- Third Section -->
          <h3 class="blog-post-title">Acquiring the Data </h3>
          <hr>
          

          <div class='row'>
            <div class='col-lg-8'>
              <p>The first objective was to collect all the reviews from all reviewers on Rotten Tomatoes (using a combination of <a href="http://scrapy.org">Scrapy</a> and <a href="https://www.selenium.dev/">Selenium</a>). Movie data (e.g., genre, synopsis) and publisher information (i.e., the organizations critics belong to) was also collected. </p>
              <p>The data were then stored in an on-disk (for simplicity) SQLite database to provide smoother analysis and access. In total 828,627 reviews were scraped. However, reviews about movies with a low total review count (under 8) or by reviewers with few total reviews (under 80) were excluded; these movies and reviewers lacked strong connections to other items in the dataset. After filtering, we end up with about 700,000 reviews on around 20,000 movies. </p>
            </div>
            <div class = 'col-lg-4'>
              <img src = 'images/rt_recommender/rt_erd.jpg'> 
              <p class='fig-caption'> Simple ERD of SQLite DB for RT data</p>
            </div>
          </div>

          <!-- Fourth Section -->
          <h3 class="blog-post-title">Collaborative Filtering </h3>
          <hr>
          <p>We can build the first iteration with just the reviews themselves as features. We need to:</p>
          <ol>
            <li> Retrieve the reviews from the DB; we need the rating ("fresh", "rotten" or "unrated"), the movie title, and the reviewer's unique id </li>
            <li> Convert the categorical ratings (“rotten” for negative reviews and “fresh” for positive reviews) into numerical data: negative reviews were coded as -1, positive as 1, and null values (i.e., no review was found) were coded as 0. </li>
            <li> Create a matrix of Movies x Reviewers, where the values are the rating assigned (-1, 0, or 1) </li>
            <li> Use this matrix to calculate an item-item similarity matrix; cosine similarity is <a href='https://www.sciencedirect.com/topics/computer-science/cosine-similarity' target="_blank">generally a good choice for sparse matrices</a> </li>
            <li> Write a quick function to look up a movie title in this cosine similarity matrix and return the titles of the nearest N movies.</li>
          </ol>

          <!-- Trigger the modal with a button -->
          <!-- Large modal -->
          <!-- Button trigger modal -->
          <button type="button" class="btn btn-primary" data-bs-toggle="modal" data-bs-target="#exampleModal">
            See example code
          </button>

          <!-- Modal -->
          <div class="modal fade" id="exampleModal" tabindex="-1" aria-labelledby="exampleModalLabel" aria-hidden="true">
            <div class="modal-dialog modal-lg modal-fullscreen-sm-down">
              <div class="modal-content">
                <div class="modal-header">
                  <h5 class="modal-title" id="exampleModalLabel">Example Code for CF Recommender </h5>
                  <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                  <code>
                  ########## 1 -- SQL Query ##########

                  import sqlite3 
                  import pandas as pd 
                  
                  # open a connection to the DB 
                  conn = sqlite3.connect('rt.db') 
                  cur = conn.cursor()

                  # target the relevant data
                  query = """ SELECT Reviews.Movie_id,
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Movies.Movie_title, 
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Reviews.Author_id,
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Freshness
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FROM Reviews JOIN Movies ON
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Movies.movie_id = Reviews.movie_id"""

                  # execute the query
                  results = cur.execute(query)

                  # and get the data
                  data = []
                  for row in results:
                  &nbsp;&nbsp;data.append(row)
                  conn.close()



                  ########## 2 -- Convert "freshness" to numeric ##########

                  import pandas as pd

                  # make a Pandas dataframe for easier handling
                  df = pd.DataFrame(data=data, columns = ['Movie_title', 'Author_id', 'Freshness'])

                  # convert the 'freshness' column
                  df.loc[df.Freshness == 'fresh', 'Freshness'] = 1
                  df.loc[df.Freshness == 'rotten', 'Freshness'] = -1
                  df.loc[df.Freshness == 'unrated', 'Freshness'] = 0


                  ########## 3 -- Create the movie x reviewer matrix ##########

                  df_pivot = pd.pivot_table(data = df, index='Movie_title', columns='Author_id', values='Freshness',
                  aggfunc='first')
                  df_pivot.fillna(0, inplace=True)


                  ########## 4 -- Calculate movie-movie cosine similarity ##########

                  from sklearn.metrics.pairwise import cosine_similarity

                  cosine_data = cosine_similarity(df_pivot)
                  df_cosine = pd.DataFrame(data=cosine_data, index=df_pivot.index, columns=df_pivot.index)


                  ########## 5 -- Look up titles to get top n recommendations ##########

                  def get_recs(movie_title, how_many = 10):
                  &nbsp;&nbsp;# simple try/except block to test if movie_title is in the dataset
                  &nbsp;&nbsp;try: 
                  &nbsp;&nbsp;&nbsp;&nbsp;a = df_cosine[movie_title].sort_values(ascending=False)
                  &nbsp;&nbsp;&nbsp;&nbsp;recs = a[1:how_many + 1]
                  &nbsp;&nbsp;&nbsp;&nbsp;return recs
                  &nbsp;&nbsp;except:
                  &nbsp;&nbsp;&nbsp;&nbsp;print('Movie Not Found!') 
                  </code>
                  <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Close</button>
                  </div>
                </div>
              </div>
            </div>
          </div>

          <div class='row py-3'>
            <div class='col-lg-8'>
              <p>Inspecting the results, the top recommendations for the horror-thriller “Us” include “Toy Story 4”. Problematic. Reviewers tend to review all big movie releases, so an element of user-choice is lost; big movies will be seen by the same people, who will go see other big movies of many different kinds. Popular movies will be lumped together regardless of content. </p>
              <p>An advantage of this is that movies of the same era will naturally end up together, since they were reviewed by the same people. We don't really need to try introducing any chronological features.</p> 

              <p>However, the disadvantages are critical. We need to add in additional features to get more meaningful recommendations. </p>
            </div>

            <div class='col-lg-4'>
              <img src='images/rt_recommender/bad_example.png'>
              <p class='fig-caption'> A disaster waiting to happen </p>
            </div>
          </div>

          <!-- Fifth Section --> 
          <h3 class="blog-post-title">Content-based Features </h3>
          <hr>
          <p>What information do we have about the actual content of the movies? We have the genre(s) and a synopsis. These turn out to be powerful additions to the system.</p>

          <p>We need to vectorize these fields. For the genres, we can get a list of all possible genres and then one-hot encode the genre column; for each genre, each movie will be assigned a 1 if it has been labelled as that genre. </p>

          <p>For the synopsis, we can use tokenize the values and use a bag-of-words approach. We also stem the tokens and remove stop words (with a few custom additions to the list). We also have to decide on an ngram range and whether or not we want to limit the vocabulary. For now, we’ll use uni-, bi- and trigrams, and we won’t impose any limits on the vocabulary (as it ultimately doesn't affect performance much, in this particular case).</p>

          <div class="btn-group py-3">
            <button type="button" class="btn btn-primary" data-bs-toggle="modal" data-bs-target="#genreModal"> Genre Code Example 
            </button>
            <button type="button" class="btn btn-primary" data-bs-toggle="modal" data-bs-target="#synopsisModal"> Synopsis Code Example </button>
          </div>

          <!-- Modal -->
          <div class="modal fade" id="genreModal" tabindex="-1" aria-labelledby="exampleModalLabel" aria-hidden="true">
            <div class="modal-dialog modal-lg modal-fullscreen-sm-down">
              <div class="modal-content">
                <div class="modal-header">
                  <h5 class="modal-title" id="exampleModalLabel">Example Code for CF Recommender </h5>
                  <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                  <code>
                  ########## 1 -- Query the DB ###########
                  
                  # same basic procedure as before
                  import sqlite3 
                  import pandas as pd 
                  
                  # open a connection
                  conn = sqlite3.connect('rt.db') 
                  cur = conn.cursor()

                  # use SQLite json_extract to get genre info stored in json
                  query = """ SELECT Movie_title,
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;json_extract(movie_info, "$.Genre")
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FROM Movies """

                  # execute the query
                  results = cur.execute(query)

                  # and get the data
                  data = []
                  for row in results:
                  &nbsp;&nbsp;data.append(row)
                  conn.close()

                  ########## 2 -- Get a list of all possible genres ##########

                  # create a df for easier handling
                  df_genres = pd.DataFrame(data=data, columns = 'Movie_title', 'Genre')
                  df_genres.Genre.fillna('NA', inplace=True)

                  # loop through and get a list of all genres in the data
                  genres_all = []

                  for value in df_genres.Genre:
                  &nbsp;&nbsp;genres = value.split(',') # the values are strings with possibly multiple genres listed
                  &nbsp;&nbsp;for j in genres:
                  &nbsp;&nbsp;&nbsp;&nbsp;genres_all.append(j.strip())

                  genres_all = list(set(genres_all))
                  genres_all.remove('NA')


                  ########## 3 -- One-hot encoding ##########

                  # create a new column for each genre in list genres_all, and fill with 1/0 values
                  for genre in genres_all:
                  &nbsp;&nbsp;df_genres[genre] = df_genres.Genre.str.contains(genre).astype(int)

                  # now clean up a bit
                  df_genres = df_genres.set_index('Movie_title')
                  df_genres = df_genres.drop('Genre', axis=1)
                  </code>
                  <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Close</button>
                  </div>
                </div>
              </div>
            </div>
          </div>

          <!-- Modal -->
          <div class="modal fade" id="synopsisModal" tabindex="-1" aria-labelledby="exampleModalLabel" aria-hidden="true">
            <div class="modal-dialog modal-lg modal-fullscreen-sm-down">
              <div class="modal-content">
                <div class="modal-header">
                  <h5 class="modal-title" id="exampleModalLabel">Example Code for CF Recommender </h5>
                  <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                  <code>
                  ########## 1 -- Load in the data ##########

                  # this time, the synopsis are stored in a csv instead of our db, so loading is simpler
                  texts = pd.read_csv('titles_synopsis.csv', index_col='Movie_title')

                  ########## 2 -- Some basic preprocessing ##########

                  texts['Synopsis'] = texts.Synopsis.fillna('None')
                  texts['Synopsis'] = texts.Synopsis.str.replace("'", ' ')
                  texts['Synopsis'] = texts.Synopsis.str.replace("'", ' ') # these are different...

                  ########## 3 -- Set up the Vectorizer ##########

                  from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
                  from nltk.stem.porter import PorterStemmer
                  from nltk.corpus import stopwords
                  import nltk

                  # custom tokenizer so we can do some stemming and filtering
                  def tokenize(text):
                  &nbsp;&nbsp;tokens = [word for word in nltk.word_tokenize(text) if len(word) > 2]
                  &nbsp;&nbsp;stemmer = PorterStemmer()
                  &nbsp;&nbsp;stems = [stemmer.stem(item) for item in tokens]
                  &nbsp;&nbsp;return stems

                  # set up the stopwords
                  stopwords = stopwords.words('english')
                  additions = ['film', 'movie', 'remain', 'america', 'filmmaker', 'actor'
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 'actress', 'finally', 'meanwhile', 'everything', 'because'
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'start', 'back', 'figure'] # additions derived by experience and trail/error

                  stopwords.extend(additions)


                  ########## 4 -- Tokenizing ##########

                  # can experiment with either CountVectorizer or TfidfVectorizer; both seem to make sense
                  syn_vectorizer = TfidfVectorizer(tokenizer=tokenize,
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stop_words=stopswords,
                  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ngram_range=(1,3)
                                                   )

                  syn_matrix = syn_vectorizer.fit_transform(texts.Synopsis)

                  </code>
                  <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Close</button>
                  </div>
                </div>
              </div>
            </div>
          </div>

          <h3 class="blog-post-title">In Search of Efficiency </h3>
          <hr>
          <p>We can concatenate these new features to the reviewer-based features from our collaborative filtering. Now we can calculate the cosine similarity matrix using the same procedure as earlier. However, we have about 20000 items (movies) in our matrix. Since each item is compared against itself, we end up with a 20000 x 20000 dense matrix, which is difficult to work with. </p>

          <p>Instead of the dense cosine similarity matrix, we can work with a sparse feature matrix. First, we use sklearn to apply SVD and k-means clustering to the reviews and create clusters rather than retaining all the reviewer information (since the most interesting result from the reviewer-based feature was the era- and popularity groupings). Next, we add in the genre and synopsis features.  </p>

          <p>Now we can query the feature matrix using basic nearest neighbors to get recommendations on the fly; this proves to be a more efficient way of getting recommendations, and without having to store a ~3GB cosine-similarity matrix. </p>

          <a href="https://share.streamlit.io/dferan/rt_recommender/main/rt_rec_app.py" class="btn btn-primary" role="button" target='_blank'>Try out an online demo!</a>

          <p> Some caveats and potential improvements:
            <ul>
              <li>The data was scraped in December 2020, so movies after that are not available; it was not designed to be extensible, though it could probably be in the future. </li>
              <li> We might look into ways to mitigate <a href="http://fsnagle.org/papers/celma2010longtail.pdf"> long-tail recommendations </a> if the standard recommendations are too expected</li>
              <li> There are still some surprising results; more thorough data auditing during the scraping process might have been of benefit</li> 
            </ul>
          </p>

          <p> Overall, however, the results are (in my estimation) comparable to those offered by Rotten Tomatoes themselves for a given movie!</p>
        </article>

    </div>




  </main>
  </body>

  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-/bQdsTh/da6pkI1MST/rWKFNjaCP5gBSY4sEBT38Q/9RBh9AH40zEOg7Hlq2THRZ" crossorigin="anonymous"></script>
</html>